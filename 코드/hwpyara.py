import streamlit as st
import olefile
import zlib
import re
import os
from io import BytesIO
from datetime import datetime

# ----------------- ë‚´ë¶€ í•¨ìˆ˜ -----------------
def extract_streams_ole(file_obj):
    if not olefile.isOleFile(file_obj):
        st.error("ìœ íš¨í•œ HWP(OLE) íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.")
        return []
    ole = olefile.OleFileIO(file_obj)
    stream_data = []
    for stream_name in ole.listdir():
        try:
            data = ole.openstream(stream_name).read()
            stream_data.append( ("/".join(stream_name), data) )
        except:
            continue
    return stream_data

def try_decompress(data):
    offsets = [i for i in range(len(data)-2) if data[i:i+2] in [b'\x78\x9c', b'\x78\x01', b'\x78\xda']]
    for offset in offsets:
        try:
            return zlib.decompress(data[offset:])
        except:
            continue
    return None

def extract_strings(data, min_length=6):
    pattern = rb"[ -~]{%d,}" % min_length
    found = re.findall(pattern, data)
    return [s.decode('utf-8', errors='ignore') for s in found if len(s.strip()) >= min_length]

def normalize(s):
    return s.strip().replace(" ", "").replace("\t", "").replace("\n", "").lower()

def is_noise(s):
    return not re.search(r'[a-zA-Z]{3,}', s) or re.search(r'[^a-zA-Z0-9 _\-.:/\\]', s)

def filter_malicious_strings(strings, safe_strings):
    filtered = []
    for s in strings:
        norm = normalize(s)
        if norm not in safe_strings and len(norm) >= 6 and not is_noise(s):
            filtered.append(s)
    return filtered

def generate_yara_rule(strings, rule_name="AutoRule_HWP", author="auto", max_strings=10):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    rule = f"rule {rule_name}_{timestamp} {{\n"
    rule += "    meta:\n"
    rule += f'        author = "{author}"\n'
    rule += f'        date = "{timestamp}"\n'
    rule += "    strings:\n"
    for idx, s in enumerate(strings[:max_strings]):
        safe = s.replace("\\", "\\\\").replace('"', '\\"')
        rule += f'        $s{idx} = "{safe}"\n'
    rule += "    condition:\n        any of them\n}"
    return rule

def load_safe_strings():
    path = "safe_strings.txt"
    if not os.path.exists(path):
        return set()
    with open(path, "r", encoding="utf-8") as f:
        return set(normalize(line) for line in f if line.strip())

def save_safe_strings_to_file(strings):
    path = "safe_strings.txt"
    existing = load_safe_strings()
    combined = existing.union(normalize(s) for s in strings)
    with open(path, "w", encoding="utf-8") as f:
        for s in sorted(combined):
            f.write(s + "\n")
    return len(combined)

# ----------------- Streamlit UI -----------------
st.title("ğŸ“„ HWP ì•…ì„±ì½”ë“œ ë¶„ì„ ë° YARA ë£° ìƒì„±ê¸°")
st.warning("âš ï¸ ì´ í”„ë¡œê·¸ë¨ì€ HWP(OLE ë°©ì‹)ë§Œ ì§€ì›í•©ë‹ˆë‹¤. HWP íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'normal_files' not in st.session_state:
    st.session_state['normal_files'] = []
if 'normal_string_counts' not in st.session_state:
    st.session_state['normal_string_counts'] = {}
if 'malicious_file' not in st.session_state:
    st.session_state['malicious_file'] = None

mode = st.radio("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["ì •ìƒ ìƒ˜í”Œ ë“±ë¡", "ì•…ì„± ìƒ˜í”Œ ë¶„ì„"])

# ----------------- ì •ìƒ ìƒ˜í”Œ ë“±ë¡ -----------------
if mode == "ì •ìƒ ìƒ˜í”Œ ë“±ë¡":
    uploaded_files = st.file_uploader(
        "ì •ìƒ HWP íŒŒì¼ ì—…ë¡œë“œ (ë“œë˜ê·¸ ì•¤ ë“œë¡­ ì§€ì›)",
        type=['hwp'],
        accept_multiple_files=True
    )

    if uploaded_files:
        if not isinstance(uploaded_files, list):
            uploaded_files = [uploaded_files]

        duplicated = []
        all_strings = set()

        for file in uploaded_files:
            if file.name in st.session_state['normal_files']:
                duplicated.append(file.name)
                continue

            streams = extract_streams_ole(file)
            file_strings = set()
            for name, raw in streams:
                decompressed = try_decompress(raw)
                data = decompressed or raw
                strings = extract_strings(data)
                file_strings.update(strings)

            if file_strings:
                st.session_state['normal_files'].append(file.name)
                st.session_state['normal_string_counts'][file.name] = len(file_strings)
                all_strings.update(file_strings)
                st.success(f"âœ… ë¶„ì„ ì™„ë£Œ: {file.name} (ì •ìƒ ë¬¸ìì—´ {len(file_strings)}ê°œ)")
            else:
                st.warning(f"âŒ ë¬¸ìì—´ì„ ì¶”ì¶œí•˜ì§€ ëª»í•¨: {file.name}")

        if duplicated:
            st.warning("âš ï¸ ì¤‘ë³µëœ íŒŒì¼ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—…ë¡œë“œ ëª©ë¡ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")

        if all_strings:
            total = save_safe_strings_to_file(all_strings)
            st.info(f"ğŸ”’ ëˆ„ì  ì •ìƒ ë¬¸ìì—´ ì´ {total}ê°œ (ì´ë²ˆ ë“±ë¡: {len(all_strings)}ê°œ)")

    if st.session_state['normal_files']:
        st.markdown("### âœ… ë“±ë¡ëœ ì •ìƒ ìƒ˜í”Œ ëª©ë¡")
        for name in st.session_state['normal_files']:
            count = st.session_state['normal_string_counts'].get(name, '?')
            st.write(f"- {name} (ì •ìƒ ë¬¸ìì—´ {count}ê°œ)")

        if st.button("ğŸ—‘ï¸ ì „ì²´ ì´ˆê¸°í™” (ì—…ë¡œë“œ ëª©ë¡ + ë¬¸ìì—´ íŒŒì¼ ì‚­ì œ)"):
            st.session_state['normal_files'] = []
            st.session_state['normal_string_counts'] = {}
            if os.path.exists("safe_strings.txt"):
                os.remove("safe_strings.txt")
            st.success("âœ… ì „ì²´ ì´ˆê¸°í™” ì™„ë£Œ: ë¬¸ìì—´ íŒŒì¼ê³¼ ì—…ë¡œë“œ ëª©ë¡ì´ ëª¨ë‘ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ----------------- ì•…ì„± ìƒ˜í”Œ ë¶„ì„ -----------------
elif mode == "ì•…ì„± ìƒ˜í”Œ ë¶„ì„":
    uploaded_file = st.file_uploader(
        "ë¶„ì„í•  HWP ì•…ì„± ìƒ˜í”Œ ì—…ë¡œë“œ (ë“œë˜ê·¸ ì•¤ ë“œë¡­ ì§€ì›)",
        type=['hwp'],
        accept_multiple_files=False
    )

    safe_strings = load_safe_strings()
    if not safe_strings:
        st.warning("âš ï¸ í˜„ì¬ ë“±ë¡ëœ ì •ìƒ ë¬¸ìì—´ í•„í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë¬¸ìì—´ì´ íƒì§€ë  ìˆ˜ ìˆìœ¼ë©°, ë¶„ì„ ì •í™•ë„ê°€ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    if uploaded_file:
        st.session_state['malicious_file'] = uploaded_file.name

        st.markdown("### ğŸš¨ ë¶„ì„ ëŒ€ìƒ ì•…ì„± ìƒ˜í”Œ")
        st.write(f"- {uploaded_file.name}")
        st.write(f"âœ… ë¶„ì„ ì™„ë£Œ: {uploaded_file.name}")

        streams = extract_streams_ole(uploaded_file)
        found = False
        for idx, (name, raw) in enumerate(streams):
            decompressed = try_decompress(raw)
            data = decompressed or raw
            strings = extract_strings(data)
            filtered = filter_malicious_strings(strings, safe_strings)
            if filtered:
                found = True
                st.subheader(f"ğŸš¨ ì˜ì‹¬ ìŠ¤íŠ¸ë¦¼: {name}")
                st.code("\n".join(filtered), language='text')
                yara_rule = generate_yara_rule(filtered)
                st.code(yara_rule, language="text")
                st.download_button(
                    f"YARA ë£° ë‹¤ìš´ë¡œë“œ: {name.replace('/', '_')}.yar",
                    yara_rule,
                    file_name=f"{idx}_{name.replace('/', '_')}.yar",
                    mime="text/plain"
                )
        if not found:
            st.info("ì˜ì‹¬ ìŠ¤íŠ¸ë¦¼ ë˜ëŠ” ì•…ì„± ë¬¸ìì—´ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    elif st.session_state['malicious_file']:
        st.markdown("### ğŸš¨ ì´ì „ì— ì—…ë¡œë“œí•œ ì•…ì„± ìƒ˜í”Œ")
        st.write(f"- {st.session_state['malicious_file']}")
